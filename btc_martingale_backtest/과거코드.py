import backtrader as bt
import pandas as pd
import logging
from scipy.stats import norm
from sklearn.model_selection import train_test_split
from backtrader.utils.date import date2num
import ccxt
from pathlib import Path
import os
import talib as ta
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestClassifier, StackingClassifier,GradientBoostingClassifier
from sklearn.linear_model import Ridge, RidgeClassifierCV
from xgboost import XGBClassifier
from backtrader.utils.py3 import string_types, integer_types
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score
from joblib import Parallel, delayed
# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ë°”ì´ë‚¸ìŠ¤ API ì„¤ì •
api_key = ""  # ë°”ì´ë‚¸ìŠ¤ API í‚¤
api_secret = ""  # ë°”ì´ë‚¸ìŠ¤ API ì‹œí¬ë¦¿ í‚¤
binance = ccxt.binance({
    'apiKey': api_key,
    'secret': api_secret,
    'enableRateLimit': True,
    'options': {'defaultType': 'future'}
})

# ê±°ë˜ ì„¤ì •
trading_symbol = 'BTCUSDT'
timeframe = '1m'  # 1ì‹œê°„ë´‰ (ë¦¬ìƒ˜í”Œë§í•˜ì—¬ ì¼ë´‰ìœ¼ë¡œ ë³€í™˜)
leverage = 10
limit = 1000
risk_per_trade = 0.02  # ê³„ì¢Œ ì”ê³ ì˜ 2% ë¦¬ìŠ¤í¬
stop_loss_pct = 0.02  # 2% ì†ì ˆ
take_profit_pct = 0.04  # 4% ìµì ˆ
lookback_period = 10000  # í•™ìŠµ ë°ì´í„° ê¸°ê°„
initial_capital = 1000  # ë°±í…ŒìŠ¤íŒ… ì´ˆê¸° ìë³¸ (USDT)
start = pd.Timestamp('2021-01-01')
end = pd.Timestamp('2025-07-17')
monte_start = pd.Timestamp('2019-09-08')
monte_end = pd.Timestamp('2020-12-31')

        
    
# ë ˆë²„ë¦¬ì§€ ë° ê²©ë¦¬ ë§ˆì§„ ì„¤ì • (CCXT ë°©ì‹)
def set_leverage_and_margin(trading_symbol, leverage):
    try:
        binance.set_leverage(leverage, trading_symbol.replace('/', ''))  # CCXT set_leverage ë©”ì„œë“œ
        binance.set_margin_mode('isolated', trading_symbol.replace('/', ''))  # ê²©ë¦¬ ë§ˆì§„ ì„¤ì •
        logger.info(f"ë ˆë²„ë¦¬ì§€ {leverage}ë°°, ê²©ë¦¬ ë§ˆì§„ ì„¤ì • ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ë ˆë²„ë¦¬ì§€/ë§ˆì§„ ì„¤ì • ì˜¤ë¥˜: {e}")

#ì°¨íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def fetch_ohlcv(trading_symbol, timeframe, limit):
    ohlcv = binance.fetch_ohlcv(trading_symbol, timeframe, limit=limit)
    df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    df.set_index('timestamp', inplace=True)
    return df


def fetch_ohlcv_between(trading_symbol, timeframe, start_date, end_date, limit=1000, max_bars=1150000):
    """
    ì§€ì •í•œ ì‹œì‘ì¼~ì¢…ë£Œì¼ê¹Œì§€ì˜ OHLCV ë°ì´í„°ë¥¼ ëª¨ë‘ ê°€ì ¸ì˜´.
    - start_date, end_date: 'YYYY-MM-DD' ë˜ëŠ” pandas.Timestamp ë“±ìœ¼ë¡œ ì…ë ¥ ê°€ëŠ¥
    """
    # ë‚ ì§œë¥¼ ms ë‹¨ìœ„ë¡œ ë³€í™˜
    if isinstance(start_date, str):
        start_ms = int(pd.Timestamp(start_date).timestamp() * 1000)
    else:
        start_ms = int(pd.to_datetime(start_date).timestamp() * 1000)
    if isinstance(end_date, str):
        end_ms = int(pd.Timestamp(end_date).timestamp() * 1000)
    else:
        end_ms = int(pd.to_datetime(end_date).timestamp() * 1000)

    all_ohlcv = []
    since = start_ms
    while True:
        ohlcv = binance.fetch_ohlcv(trading_symbol, timeframe, since=since, limit=limit)
        if not ohlcv:
            break
        # ê¸°ê°„ ë‚´ ë°ì´í„°ë§Œ í•„í„°ë§
        ohlcv = [row for row in ohlcv if row[0] <= end_ms]
        all_ohlcv += ohlcv
        if len(ohlcv) < limit or (all_ohlcv and all_ohlcv[-1][0] >= end_ms) or len(all_ohlcv) >= max_bars:
            break
        since = all_ohlcv[-1][0] + 1  # ë§ˆì§€ë§‰ ìº”ë“¤ ì´í›„ë¶€í„°

    # DataFrame ë³€í™˜
    df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    df.set_index('timestamp', inplace=True)
    return df

# ê¸°ê´€ (í—¤ì§€í€íŠ¸ì—ì„œ ì‚¬ìš©í•œë‹¤ê³  í•˜ëŠ” íŒŒë¼ë¯¸í„° ê°’ì„ ì ìš©í•œ)ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜



def monte_carlo_var_parallel(close_series, investment, confidence_level=0.95, days=30, num_simulations=10000, n_jobs=-1):
    """
    ë³‘ë ¬ ì—°ì‚° ê¸°ë°˜ Monte Carlo VaR ê³„ì‚°
    - close_series: ê³¼ê±° ì¢…ê°€ (pd.Series)
    - investment: íˆ¬ì ê¸ˆì•¡ ($)
    - confidence_level: VaR ì‹ ë¢°ë„ (ì˜ˆ: 0.99)
    - days: ì˜ˆì¸¡ ê¸°ê°„ (ì˜ˆ: 10)
    - num_simulations: ì‹œë®¬ë ˆì´ì…˜ ë°˜ë³µ íšŸìˆ˜ (ì˜ˆ: 100_000)
    - n_jobs: ë™ì‹œì— ì‚¬ìš©í•  CPU ì½”ì–´ ìˆ˜, -1ì´ë©´ ì „ì²´ ì‚¬ìš©
    """

    log_returns = np.log(close_series / close_series.shift(1)).dropna()
    mu = log_returns.mean()
    sigma = log_returns.std()
    last_price = close_series.iloc[-1]

    # ë‹¨ì¼ ì‹œë®¬ë ˆì´ì…˜ í•¨ìˆ˜
    def simulate_mc():
        returns = np.random.normal(mu, sigma, days)
        return last_price * np.exp(np.cumsum(returns))[-1]  # ë§ˆì§€ë§‰ ê°€ê²©ë§Œ ì‚¬ìš©

    # ë³‘ë ¬ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    simulated_end_prices = Parallel(n_jobs=n_jobs, backend="loky")(
        delayed(simulate_mc)() for _ in range(num_simulations)
    )

    ending_returns = np.array(simulated_end_prices) / last_price - 1
    var_percent = np.percentile(ending_returns, (1 - confidence_level) * 100)
    var_dollar = investment * -var_percent  # ì†ì‹¤ê°’ì´ë¯€ë¡œ -ë¶€í˜¸ ì²˜ë¦¬

    return var_dollar, var_percent, simulated_end_prices
 



def calculate_indicators(df):
    # Copy DataFrame to avoid modifying original
    df = df.copy()
    
    close = df['close'].values
    high = df['high'].values
    low = df['low'].values
    open = df['open'].values
    
    # RSI
    df['rsi'] = ta.RSI(close, timeperiod=14)
    
    # SMA and EMA
    df['sma'] = ta.SMA(close, timeperiod=20)
    df['ema'] = ta.EMA(close, timeperiod=20)
    
    # Bollinger Bands
    upper, middle, lower = ta.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2)
    df['bb_upper'] = upper
    df['bb_lower'] = lower
    df['bb_mid'] = middle

    # Squeeze Momentum Indicator
    length = 20
    mult = 2.0
    lengthKC = 20
    multKC = 1.0
    useTrueRange = True

    # Bollinger Bands
    basis = ta.SMA(close, timeperiod=length)
    dev = mult * ta.STDDEV(close, timeperiod=length)
    df['upperBB'] = basis + dev
    df['lowerBB'] = basis - dev

    # Keltner Channels
    ma = ta.SMA(close, timeperiod=lengthKC)
    range1 = ta.TRANGE(open, low, close) if useTrueRange else (high - low)
    rangema = ta.SMA(range1, timeperiod=lengthKC)
    df['upperKC'] = ma + rangema * multKC
    df['lowerKC'] = ma - rangema * multKC

    # Squeeze conditions
    df['sqzOn'] = (df['lowerBB'] > df['lowerKC']) & (df['upperBB'] < df['upperKC'])
    df['sqzOff'] = (df['lowerBB'] < df['lowerKC']) & (df['upperBB'] > df['upperKC'])
    df['noSqz'] = ~df['sqzOn'] & ~df['sqzOff']

    # Squeeze Momentum (val)
    highest_high = ta.MAX(high, timeperiod=lengthKC)
    lowest_low = ta.MIN(low, timeperiod=lengthKC)
    avg_hl = (highest_high + lowest_low) / 2
    avg_sma = ta.SMA(close, timeperiod=lengthKC)
    df['val'] = ta.LINEARREG(close - (avg_hl + avg_sma) / 2, timeperiod=lengthKC)

    # bcolor: Momentum direction
    df['bcolor'] = np.where(
        df['val'] > 0,
        np.where(df['val'] > df['val'].shift(1), 1, 2),  # 1: lime (increasing), 2: green (decreasing)
        np.where(df['val'] < df['val'].shift(1), 3, 4)   # 3: red (decreasing), 4: maroon (increasing)
    )

    # scolor: Squeeze state
    df['scolor'] = np.where(df['noSqz'], 1, np.where(df['sqzOn'], 2, 3))  # 1: blue, 2: black, 3: gray

    # Highest and lowest prices
    df['highest_price'] = high
    df['lowest_price'] = low
    
    
    
    
    # atr
    
    df['atr'] = ta.ATR(df['high'], df['low'], df['close'], timeperiod=14)

    # Log NaN counts
    
    # logger.info(f"Indicator NaN counts:\n{df.isna().sum()}")
    
    
    
    return df


def train_ml_models(df):
    n = 240
    rolling_max = df['close'].shift(-1).rolling(window=n, min_periods=1).max()
    df['target'] = (rolling_max >= df['close'] * 1.004).astype(int)
    features = ['close', 'rsi', 'sma', 'ema', 'bb_upper', 'bb_lower', 'bb_mid', 
                'val', 'bcolor', 'scolor', 'volume', 'atr']
    
    # ë¶„í¬ í™•ì¸
    # logger.info(f"df['target'].value_counts() : {df['target'].value_counts()}")
    
    print(f"ì „ì²´ ë°ì´í„° ê¸¸ì´: {len(df)}")
    
    
    df_clean = df.dropna()
    
    # print(f"NaN ì œê±° í›„ ë°ì´í„° ê¸¸ì´: {len(df_clean)}")
    # logger.info(f"Indicator NaN counts:\n{df_clean.isna().sum()}")
    
    
    # if df_clean.empty:
    #     raise ValueError("No valid data after removing NaN values.")
    X = df_clean[features]
    y = df_clean['target']
    
    # logger.info(f"y ê°’ : {y}")
    # if y.nunique() < 2:
    #     raise ValueError("Target must have at least two classes")

    tscv = TimeSeriesSplit(n_splits=5)
    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
    scores = []
    for train_idx, test_idx in tscv.split(X):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        rf.fit(X_train, y_train)
        y_pred = rf.predict(X_test)
        
        # í´ë˜ìŠ¤ 1ì¼ í™•ë¥  ì˜ˆì¸¡
        y_prob = rf.predict_proba(X_test)[:, 1]  # í´ë˜ìŠ¤ 1ì˜ í™•ë¥ 
        
        score = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        scores.append(score)
        print(f"Fold score: {score:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, F1: {f1:.4f}")
        print(f"í´ë˜ìŠ¤ 1ì¼ í‰ê·  í™•ë¥ : {np.mean(y_prob):.4f}")
        
    print(f"í‰ê·  êµì°¨ê²€ì¦ ì ìˆ˜: {sum(scores)/len(scores):.4f}")
    # ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… í•™ìŠµ
    rf.fit(X, y)
    
  
    return features, rf



class MLFuturesStrategy(bt.Strategy):
    params = dict(
        lookback_period=lookback_period,
        inputTrade=10,          # ìµœëŒ€ ì§„ì… íšŸìˆ˜
        additionalEntryPrice=1200,  # ë¬¼íƒ€ê¸° í•œë„ (ê°€ê²© ë‹¨ìœ„)
        profit=1.01,            # ìµì ˆ ë¹„ìœ¨
        leverage=10,
        dividedLongCount=20,
        montecarlo_var_dollar = 0.0,
        montecarlo_var_percent = 0.0
    )

    def __init__(self):
        self.entryCount = 0
        self.entryPriceSum = 0.0
        self.avgPrice = 0.0
        self.is_trained = False
        self.order = None
        self.trades = []
        self.stopless = 0.0
        self.portfolio_values = []
        self._trade_id = 0
        
        self.entry_price_sum = 0.0
        self.total_entry_count = 0
        self.initial_entry_price = 0.0
        self.second_entry_price = 0.0
        self.is_trading_active = True
        self.dataclose = self.datas[0].close
        self.datahigh = self.datas[0].high
        self.datalow = self.datas[0].low
        self.datavolume = self.datas[0].volume
        self.features = ['close', 'rsi', 'sma', 'ema', 'bb_upper', 'bb_lower', 'bb_mid', 
                'val', 'bcolor', 'scolor', 'volume']
        self.rf = None
        self.var_history = []  # âœ… ê° ê±°ë˜ ë•Œì˜ VaR ëˆ„ì  ì €ì¥ì†Œ
        self.montecarlo_var_dollar = None
        self.montecarlo_var_percent = None
        
    def next(self):
        # ë°ì´í„°í”„ë ˆì„ ì¤€ë¹„
        df = pd.DataFrame({
            'open': self.datas[0].open.get(size=self.params.lookback_period),
            'high': self.datas[0].high.get(size=self.params.lookback_period),
            'low': self.datas[0].low.get(size=self.params.lookback_period),
            'close': self.datas[0].close.get(size=self.params.lookback_period),
            'volume': self.datas[0].volume.get(size=self.params.lookback_period)
        }, index=self.datas[0].datetime.get(size=self.params.lookback_period))
        df.index = pd.to_datetime([bt.num2date(x) for x in df.index])

        df = calculate_indicators(df)  # ì§€í‘œ ê³„ì‚° í•¨ìˆ˜

       # ëª¨ë¸ í•™ìŠµ (ìµœì´ˆ 1íšŒë§Œ ìˆ˜í–‰)
        if not self.is_trained:
            try:
                features, rf = train_ml_models(df)
                self.is_trained = True
                self.features = features
                self.rf = rf
                self.log("Models trained successfully")
            except Exception as e:
                self.log(f"Model training failed: {e}")
                return

        val = df['val'].iloc[-1]
        atr = df['atr'].iloc[-1]
        latest_data = df[self.features].iloc[-1:]
        proba = self.rf.predict_proba(latest_data)[0][1]
        
        close_price = self.datas[0].close[0]
        open_price = self.datas[0].open[0]

        
        
        # if len(df) >= 100000:
        #     try:
                
        # ì „ëµ ë³€ìˆ˜ì— ì €ì¥ (ìµœì‹ )
        var_dollarForBacktest, var_pctForBacktest, paths = monte_carlo_var_parallel(
            close_series=df['close'][-1000:],   # ë°ì´í„° ê°œìˆ˜ 1000~3000ê°œ ë“±
            investment=(self.broker.getvalue() * self.params.leverage),
            confidence_level=0.99,              # â† ê¶Œì¥ ì‹ ë¢°êµ¬ê°„(99% ë“±)
            days=1,
            num_simulations=100000,             # â† ë³‘ë ¬ì´ë¼ ì‹œê°„ ë¶€ë‹´ â†“ ê°€ëŠ¥
            n_jobs=-1                           # CPU ì „ì²´ ì‚¬ìš© (8ì½”ì–´ë©´ 8ê°œ)
        )
        self.montecarlo_var_dollar = var_dollarForBacktest
        self.montecarlo_var_percent = var_pctForBacktest
                
                
                # log í™•ì¸
                # self.log(f"Monte Carlo VaR %: {var_dollar:.2f} ({var_pct:.2%})")

                # ì¡°ê±´ ì°¨ë‹¨ ì˜ˆì‹œ: VaRì´ í˜„ì¬ ìë³¸ì˜ 4% ì´ìƒì´ë©´ ì§„ì… ê¸ˆì§€
                # if var_dollar > self.broker.getvalue() * 0.04:
                    # self.log(f"VaR too high (${var_dollar:.2f}). Skipping entry.")
                    # return

            # except Exception as e:
            #     # self.log(f"Monte Carlo VaR calculation failed: {e}")
            #     return
        var_dollar = self.params.montecarlo_var_dollar
        var_pct = self.params.montecarlo_var_percent
        
        # ì¡°ê±´ ì°¨ë‹¨ ì˜ˆì‹œ: VaRì´ í˜„ì¬ ìë³¸ì˜ 4% ì´ìƒì´ë©´ ì§„ì… ê¸ˆì§€
        # if var_dollar > self.broker.getvalue() * 0.1:
        #     return
        # ì§„ì… ì¡°ê±´
        

        # position_size = max((self.params.dividedLongCount and (self.broker.getvalue() * self.params.leverage) / self.params.dividedLongCount) / close_price, 0.0001)
        position_size = ((self.broker.getvalue() * self.params.leverage) / self.params.dividedLongCount) / close_price
        # logger.info(f'initial_capital : {self.broker.getvalue()}')
        can_enter = self.entryCount < self.params.inputTrade and position_size > 0
        if can_enter:
            # ì²« ì§„ì… ë˜ëŠ” ì¶”ê°€ ì§„ì…
            # logger.info(f'var_dollars : {var_dollar}')
            if self.entryCount == 0 and val > 0 and close_price > open_price and self.total_entry_count == 0 and var_dollar <= self.broker.getvalue() * 0.1 and var_dollarForBacktest <= self.broker.getvalue() * 0.1:
                
                self.var_history.append(var_dollar)
                # logger.info(f'self.var_history : {self.var_history}')
                self.montecarlo_var_dollar = var_dollar
                self.montecarlo_var_percent = var_pct
                self.entryPriceSum = close_price
                self.total_entry_count = 1
                self.avgPrice = self.entryPriceSum/self.total_entry_count
                self.buy(size=position_size)
                self.entryCount += 1
                self.log(f"Entry 1 at {close_price:.2f}, avgPrice: {self.avgPrice:.2f}, self.entryCount : {self.entryCount}, position : {position_size}, var_dollar : {var_dollarForBacktest}")
            
            # ë¬¼íƒ€ê¸° ì¡°ê±´: í˜„ì¬ê°€ê°€ í‰ê· ê°€ì—ì„œ ì¶©ë¶„íˆ ë‚´ë ¤ì™”ëŠ”ì§€
            if self.entryCount >= 1  and self.entryCount < self.params.inputTrade :
                price_gap = self.avgPrice - close_price
                self.stopless = self.params.additionalEntryPrice - (2 * atr) 
                gap = price_gap >  self.stopless * self.entryCount
                # if gap :
                #     logger.info(f'gap : {gap}')
                
                if price_gap > self.stopless * self.entryCount :
                    
                    self.entryPriceSum = self.entryPriceSum + close_price
                    self.total_entry_count = self.total_entry_count + 1
                    self.avgPrice = self.entryPriceSum / self.total_entry_count
                    self.buy(size=position_size)
                    self.entryCount += 1
                    self.log(f"Entry {self.entryCount} at {close_price:.2f}, avgPrice: {self.avgPrice:.2f}")
        
        # ìµì ˆ / ì²­ì‚° ì¡°ê±´
        if self.entryCount >= 2 and (close_price > self.avgPrice):
            # ì´ˆê¸° íˆ¬ì… ë¬¼ëŸ‰ ì œì™¸í•˜ê³  ì²­ì‚°
            qty = (position_size * (self.entryCount - 1))
            qty_percent = qty / (position_size * self.entryCount) * 100
            qty_sell = (position_size * self.entryCount) * qty_percent
            self.sell(size=qty)
            self.log(f"Partial exit at {close_price:.2f}, avgPrice: {self.avgPrice:.2f}, entryCount : {self.entryCount}, , position : {position_size * self.entryCount}, qty : {qty}")
            self.entryCount = self.entryCount - (self.entryCount - 1)
            
        if self.entryCount == 1 and (close_price >= self.avgPrice * self.params.profit ):
            
            self.close()
            self.log(f"Exit all at {close_price:.2f}, avgPrice: {self.avgPrice:.2f}")
            self.entryCount = 0
            self.avgPrice = 0
            self.entryPriceSum = 0
            self.total_entry_count = 0
            
        if self.broker.getvalue() <= 0 :
            logger.warning(f'margin Call : {self.broker.getvalue()}, close : {close_price}')
            

        
    
    def log(self, txt):
        dt = self.datas[0].datetime.date(0)
        
        print(f'{dt.isoformat()} {txt}')
        
        


def prepare_backtrader_data(df):
    if df.empty:
        raise ValueError("No data fetched from Binance. Check API keys or network connection.")

    logger.info(f"Initial DataFrame: {len(df)} rows, from {df.index[0]} to {df.index[-1]}")

    df_backtrader = df[['open', 'high', 'low', 'close', 'volume']].resample('1min').agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    }).dropna()

    logger.info(f"After resampling: {len(df_backtrader)} rows, from {df_backtrader.index[0]} to {df_backtrader.index[-1]}")

    df_backtrader.index = df_backtrader.index.tz_localize(None)
    df_backtrader.index.name = 'datetime'

    if not df_backtrader.index.is_monotonic_increasing:
        logger.warning("Index is not monotonic, sorting...")
        df_backtrader = df_backtrader.sort_index()

    df_backtrader = calculate_indicators(df_backtrader)
    logger.info(f"After indicators: {len(df_backtrader)} rows, NaN counts:\n{df_backtrader.isna().sum()}")

    df_backtrader = df_backtrader.loc[start:end]
    logger.info(f"After date filtering: {len(df_backtrader)} rows, from {df_backtrader.index[0]} to {df_backtrader.index[-1]}")

    if df_backtrader.empty:
        raise ValueError(f"No data available between {start} and {end}")

    for col in ['rsi', 'sma', 'ema', 'bb_upper', 'bb_lower', 'bb_mid', 'upperBB', 'lowerBB', 'upperKC', 'lowerKC']:
        if col in df_backtrader.columns:
            df_backtrader[col] = df_backtrader[col].bfill().fillna(0)
    df_backtrader['val'] = df_backtrader['val'].fillna(0)
    df_backtrader['bcolor'] = df_backtrader['bcolor'].fillna(0)
    df_backtrader['scolor'] = df_backtrader['scolor'].fillna(0)
    df_backtrader['sqzOn'] = df_backtrader['sqzOn'].fillna(0)
    df_backtrader['sqzOff'] = df_backtrader['sqzOff'].fillna(0)
    df_backtrader['noSqz'] = df_backtrader['noSqz'].fillna(0)
    df_backtrader['atr'] = df_backtrader['atr'].fillna(0)

    numeric_cols = [col for col in df_backtrader.columns if col not in ['sqzOn', 'sqzOff', 'noSqz']]
    for col in numeric_cols:
        df_backtrader[col] = pd.to_numeric(df_backtrader[col], errors='coerce')

    required_cols = ['open', 'high', 'low', 'close', 'volume', 'rsi', 'sma', 'ema',
                    'bb_upper', 'bb_lower', 'bb_mid', 'val', 'bcolor', 'scolor',
                    'highest_price', 'lowest_price', 'upperBB', 'lowerBB',
                    'upperKC', 'lowerKC', 'sqzOn', 'sqzOff', 'noSqz', 'atr']
    missing_cols = [col for col in required_cols if col not in df_backtrader.columns]
    if missing_cols:
        raise ValueError(f"Missing columns: {missing_cols}")

    df_backtrader = df_backtrader.dropna()
    if df_backtrader.empty:
        raise ValueError("DataFrame is empty after dropping NaNs")

    logger.info(f"DataFrame: {len(df_backtrader)} rows, from {df_backtrader.index[0]} to {df_backtrader.index[-1]}")
    return df_backtrader


def save_csvForOHLCV(df):
    current_path = Path(os.getcwd())
     # Save to CSV
    # csv_dir = Path('~/.ì•Œê³ ë¦¬ì¦˜íŠ¸ë ˆì´ë”©btc').expanduser()
    result_dir = current_path / 'result_btcë¬¼íƒ€ê¸°'
    csv_path = result_dir / 'ohlcv.csv'
    result_dir.mkdir(parents=True, exist_ok=True)

    
    # âœ… timestamp ì»¬ëŸ¼ì´ ì—†ê³ , ì¸ë±ìŠ¤ê°€ datetimeì´ë¼ë©´ ì»¬ëŸ¼ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ê¸°
    if isinstance(df.index, pd.DatetimeIndex):
        df = df.copy()
        df.reset_index(inplace=True)
        df.rename(columns={'index': 'timestamp'}, inplace=True)
    
    if csv_path.exists():
        os.remove(csv_path)
        logger.info(f"Deleted existing CSV: {csv_path}")

    if not df.empty:
        df.to_csv(csv_path, index=False)
        logger.info(f"Combined CSV saved: {csv_path}")
    else:
        logger.warning("No data to save to CSV.")
    
    
    
    

    
class ArithmeticReturns(bt.Analyzer): # âœ… í•´ë‹¹ í´ë˜ìŠ¤ëŠ” ì „ëµ(bt.strategyë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ëŠ” í´ë˜ìŠ¤)ì´ ì‹¤í–‰ë˜ê¸° ì „ì— ì „ëµ ê°’ì„ ê°€ì ¸ì˜¤ë¯€ë¡œ 
                                      # ì „ëµ ì‹¤í–‰ í›„ì˜ ê°’ì„ ê°€ì ¸ì˜¤ê³  ì‹¶ìœ¼ë©´ stop() í•¨ìˆ˜ì—ì„œ ê°’ì„ ë¶ˆëŸ¬ì˜¬ ê²ƒ
    def __init__(self):
        self.initial_cash = self.strategy.broker.getcash() # âœ… ì´ˆê¸° ì˜ˆì‚°, ì „ëµì´ ì‹¤í–‰ë˜ê¸° ì „ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆëŠ” ê°’ì´ë¯€ë¡œ initì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥
        self.net_profit_percent = 0.0
        self.net_profit = 0

    def notify_cashvalue(self, cash, value):
        self.final_value = value

    def stop(self):
        self.net_profit_percent = ((self.final_value - self.initial_cash) / self.initial_cash) * 100
        self.net_profit = self.final_value - self.initial_cash

    def get_analysis(self):
        return {'net_profit_percent': self.net_profit_percent,  'net_profit': self.net_profit}
                

class MonteCarloVaRAnalyzer(bt.Analyzer):
    def __init__(self):
        self.var_value = 0.0
        self.var_percent = 0.0
        self.var_history = []            # âœ… ê±°ë˜ë³„ VaR ì €ì¥ ë¦¬ìŠ¤íŠ¸
        self.avg_var_result = None       # âœ… í‰ê·  ì €ì¥ ë³€ìˆ˜
        
    # def notify_strategy(self, strategy):
        
    #     self.var_history = strategy.var_history
        
    #     self.var_value = strategy.montecarlo_var_dollar
    #     self.var_percent = strategy.montecarlo_var_percent
    
        
    def stop(self):
        strategy = self.strategy  # ì´ì œ ì™„ì „íˆ attach ë¨
        
        
        self.var_history = strategy.var_history
        self.var_value = strategy.montecarlo_var_dollar
        self.var_percent = strategy.montecarlo_var_percent
        
        
        if self.var_history:
            self.avg_var_result = np.mean(self.var_history)
            print(f"âœ… í‰ê·  VaR (ì´ {len(self.var_history)} ê±°ë˜): ${self.avg_var_result:.2f}")
        else:
            print("âŒ ê±°ë˜ ì¤‘ ì €ì¥ëœ VaR ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print(f'self.var_history : {self.var_history}')
            
    def get_analysis(self):
        return {
            'var_value': self.var_value,
            'var_percent': self.var_percent,
            'avg_var': self.avg_var_result,
            'var_history': self.var_history,
            
        }
        
        


def run_backtest(df):
    logger.info("run_backtest ì‹œì‘")
    df_backtrader = prepare_backtrader_data(df)
    logger.info(f"df_backtrader ì¤€ë¹„ ì™„ë£Œ: {len(df_backtrader)} í–‰, {df_backtrader.index[0]} ~ {df_backtrader.index[-1]}")


    mc_df = df.loc[monte_start:monte_end]
    
    
    if len(df_backtrader) < lookback_period:
        raise ValueError(f"ë°ì´í„° ë¶€ì¡±: {len(df_backtrader)} í–‰, í•„ìš”: {lookback_period}")
    
    
    
    # logger.info(f'mc_df  : {mc_df}')
    
    bt_df = df_backtrader.loc[start:end]
    
    # logger.info(f'bt_df  : {bt_df}')
    
    # (í—¤ì§€í€ë“œì—ì„œ ì‚¬ìš©í•œë‹¤ê³ í•˜ëŠ” íŒŒë¼ë¯¸í„° ê°’ì„ ì ìš©í•œ ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜)
                
    if mc_df is None or mc_df.empty or len(mc_df['close']) < 2:
        raise ValueError("Monte Carlo ì‹œë®¬ë ˆì´ì…˜ìš© close ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        var_dollar, var_pct, paths = monte_carlo_var_parallel(
            close_series=mc_df['close'],
            investment=(initial_capital * 10),
            confidence_level=0.99,
            days=10,
            num_simulations=100000,
            n_jobs=-1
        )
        
        
        
    logger.info(f'var_dollar : {var_dollar}')
    cerebro = bt.Cerebro()  # exactbars ì œê±°
    logger.info("Cerebro ì´ˆê¸°í™” ì™„ë£Œ")

    data_feed = bt.feeds.PandasData(
        dataname=bt_df,
        fromdate=bt_df.index[0].to_pydatetime(),
        todate=bt_df.index[-1].to_pydatetime(),
        timeframe=bt.TimeFrame.Minutes,
        compression=5
    )
    
    
    
    
    logger.info("ë°ì´í„° í”¼ë“œ ìƒì„± ì™„ë£Œ")

    cerebro.adddata(data_feed)
    logger.info("ë°ì´í„° í”¼ë“œ ì¶”ê°€ ì™„ë£Œ")

    
    cerebro.broker.setcash(initial_capital)
    cerebro.broker.setcommission(commission=0.0005, leverage=leverage, margin=0 / leverage )
    cerebro.broker.set_slippage_perc(perc = 0.00015)
    logger.info("ë¸Œë¡œì»¤ ì„¤ì • ì™„ë£Œ")

    cerebro.addanalyzer(ArithmeticReturns, _name='arithmetic_returns')
    cerebro.addanalyzer(MonteCarloVaRAnalyzer, _name='mc_var')
    cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe')
    cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')
    cerebro.addanalyzer(bt.analyzers.Returns, _name='returns')
    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')
    logger.info("ë¶„ì„ê¸° ì¶”ê°€ ì™„ë£Œ")

    try:
        cerebro.addstrategy(MLFuturesStrategy, lookback_period=lookback_period, montecarlo_var_dollar = var_dollar,
        montecarlo_var_percent = var_pct)  # lookback_period ì¶•ì†Œ
        logger.info("MLFuturesStrategy ì „ëµ ë“±ë¡ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ì „ëµ ë“±ë¡ ì‹¤íŒ¨: {e}")
        raise

    logger.info(f"ë°ì´í„° í”¼ë“œ ë²”ìœ„: {bt_df.index[0]} ~ {bt_df.index[-1]}, ê¸¸ì´={len(bt_df)}")
    try:
        logger.info("ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œì‘")
        results = cerebro.run()
        logger.info("ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise

    strat = results[0]
    mc_result = strat.analyzers.mc_var.get_analysis()
    avg_var = mc_result.get('avg_var', None)
    last_var = mc_result.get('var_value', None)
    var_per = mc_result.get('var_percent', None)
    sharpe = strat.analyzers.sharpe.get_analysis().get('sharperatio', 0.0) or 0.0
    drawdown = strat.analyzers.drawdown.get_analysis().get('max', {}).get('drawdown', 0.0)
    drawdown_money = strat.analyzers.drawdown.get_analysis().get('max', {}).get('moneydown')
    total_return = strat.analyzers.returns.get_analysis().get('rtot', 0.0) * 100
    arithmetic_profit_percent = strat.analyzers.arithmetic_returns.get_analysis().get('net_profit_percent', 0.0)
    arithmetic_profit = strat.analyzers.arithmetic_returns.get_analysis().get('net_profit', 0.0)
    trades = strat.analyzers.trades.get_analysis().get('total', {}).get('total', 0)

    logger.info(f"ìƒ¤í”„ ë¹„ìœ¨: {sharpe:.2f}")
    logger.info(f"ìµœëŒ€ ë‚™í­: {drawdown:.2f}%, {drawdown_money}")
    logger.info(f"ì´ ìˆ˜ìµë¥ (ë¡œê·¸): {total_return:.2f}%")
    logger.info(f"ì´ ìˆ˜ìµë¥ (ì‚°ìˆ ): {arithmetic_profit_percent:.2f}%")
    logger.info(f"ì´ ìˆ˜ìµ: {arithmetic_profit:.2f}")
    logger.info(f"ì´ ê±°ë˜ íšŸìˆ˜: {trades}")
    if avg_var is not None:
        logger.info(f"ğŸ“Š í‰ê·  VaR (ëˆ„ì  ì „ì²´ ê±°ë˜): ${avg_var:.2f}")
    
    if last_var is not None:
        logger.info(f"ğŸ“Œ ë§ˆì§€ë§‰ ê±°ë˜ì˜ VaR: ${last_var:.2f}")
  
    if var_per is not None:
        logger.info(f"ğŸ“Š í‰ê·  VaR (ëˆ„ì  ì „ì²´ ê±°ë˜) %: ${var_per:.2f}%")
   
    
    
    if trades == 0:
        logger.warning("ë°±í…ŒìŠ¤íŠ¸ ì¤‘ ê±°ë˜ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ")

    return strat

def main():
    try:
        set_leverage_and_margin(trading_symbol, leverage)
        
        # ëª¬í…Œì¹´ë¥¼ë¡œ ëª¨ë¸ ì°¸ê³ ìš© ë°ì´í„°ë¥¼ í•¨ìˆ˜ì—ì„œ ì§ì ‘ ë¶ˆëŸ¬ì˜¬ ê²½ìš°
        # mc_df = fetch_ohlcv_between(
        #     symbol='BTC/USDT',
        #     timeframe='1m',
        #     start='2019-09-08',
        #     end='2020-12-31',
        #     max_bars=500_000   # ì¶©ë¶„íˆ í° ê°’ìœ¼ë¡œ ì„¤ì •
        # )
        
        
        # df = fetch_ohlcv_between(trading_symbol, timeframe, monte_start, end, max_bars=3985920)
        # save_csvForOHLCV(df)
        df = pd.read_csv('result_btcë¬¼íƒ€ê¸°/ohlcv.csv',
                        index_col='timestamp',      # ë‚ ì§œ ì»¬ëŸ¼ì´ë¦„ì— ë§ê²Œ ì§€ì •
                        parse_dates=['timestamp'],  # ë‚ ì§œ ì»¬ëŸ¼ì„ ì‹¤ì œ ë‚ ì§œíƒ€ì…ìœ¼ë¡œ ë³€í™˜
                        encoding='utf-8'           # í•„ìš”ì‹œ ì¸ì½”ë”© ì¡°ì •
                        )
        
        # save_csvForOHLCV(df)
        logger.info(f"Fetched data: {len(df)} rows, from {df.index[0]} to {df.index[-1]}")
        
        
        
        run_backtest(df)
    except Exception as e:
        logger.error(f"Main execution failed: {e}")

if __name__ == "__main__":
    main()